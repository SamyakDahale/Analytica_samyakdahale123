{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6e3bed-f7fb-4cef-8b38-6ff8729aee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id Website Link                        Name of the Book Name of the Author  \\\n",
      "0   1         Link  Gandhi's Autobiography : Moral Lessons     K. D. Gangrade   \n",
      "1   2         Link                            Truth is God       M. K. Gandhi   \n",
      "2   3         Link                                  अलंकार          प्रेमचन्द   \n",
      "3   4         Link                                   गोदान          प्रेमचन्द   \n",
      "4   5         Link     Sarthashri Mahabharata Subhashitani            Unknown   \n",
      "\n",
      "   Number of Pages                         Publishers          Language  \n",
      "0              101    Gandhi Smriti and Darshan Samit           English  \n",
      "1              163         Navajivan Publishing House           English  \n",
      "2              154                            Unknown             Hindi  \n",
      "3              611                            Unknown             Hindi  \n",
      "4              224                     केशवभिकाजीढवळे  Sanskrit/Marathi  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'E:\\MGM UDICT\\Analytica\\c.xlsx'  \n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3616bb08-053c-4ce8-bbac-cde1b2a73a98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T16:12:56.559474Z",
     "start_time": "2024-10-23T16:12:10.836616Z"
    }
   },
   "source": [
    "import os # not needed\n",
    "import pdfplumber\n",
    "\n",
    "# Directory where the downloaded books are stored\n",
    "directory = 'E:\\MGM UDICT\\Analytica'\n",
    "\n",
    "# Function to extract text based on file type\n",
    "def extract_text_from_file(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            return ''.join([page.extract_text() for page in pdf.pages])\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Iterate through all files in the directory and extract text\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if filename.endswith(('.pdf')):\n",
    "        text = extract_text_from_file(file_path)\n",
    "        print(f\"Extracted text from {filename}:\")\n",
    "        print(text[:500])  # Print first 500 characters of the extracted text\n",
    "        print('-' * 50)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from alankar.pdf:\n",
      "अलंकार\n",
      "प्रेमचंद\n",
      "www.hindustanbooks.com 11\n",
      "अध्याय\n",
      "उन ददनों नील नदी के तट पर बहुतसे तपस्वी रहा करत े थे। दोनों ही ककनारों पर ककतनी ही झोंपड़ियां\n",
      "थो़िीथो़िी दरू पर बनी हुई थीं। तपस्वी लोग इनहीं में एकानतवास करत े थे और जरूरत प़िने पर एकदसू रे\n",
      "की सहायता करत े थे। इनहीं झोंपड़ियों के बीच में जहातं हां गगरजे बने हुए थे। परायः सभी गगरजाघरों पर\n",
      "सलीब का आकार ददखाई देता था। धमोर्तसवस ों पर साधसु नत दरू दरू स े वहां आ जात े थे। नदी के ककनारे\n",
      "जहांतहां मठ भी थे। जहां तपस्वी लोग अकेले छोटीछोटी गफु ाओं में ससद\n",
      "--------------------------------------------------\n",
      "Extracted text from GandhiAutobio_morallessons.pdf:\n",
      "Gandhi's Autobiography :\n",
      "Moral Lessons\n",
      "By : K. D. Gangrade\n",
      "Published by :\n",
      "Gandhi Smriti and Darshan Samiti\n",
      "Rajghat, New Delhi 11000Gandhi's Autobiography : Moral Lessons\n",
      "FOREWORD\n",
      "MAHATMA Gandhi's autobiography, My Experiments with Truth, has attracted\n",
      "worldwide attention as a classic of modern times for the remarkable insights it\n",
      "offers into the progression of human soul in its resolute march to relate itself\n",
      "to the ever-changing ethos in the course of life's journey. Over the years, this\n",
      "record\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m file_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, filename)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.pdf\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[1;32m---> 20\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[43mextract_text_from_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracted text from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(text[:\u001B[38;5;241m500\u001B[39m])  \u001B[38;5;66;03m# Print first 500 characters of the extracted text\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[1], line 11\u001B[0m, in \u001B[0;36mextract_text_from_file\u001B[1;34m(file_path)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file_path\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.pdf\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m pdfplumber\u001B[38;5;241m.\u001B[39mopen(file_path) \u001B[38;5;28;01mas\u001B[39;00m pdf:\n\u001B[1;32m---> 11\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[43m[\u001B[49m\u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpage\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpages\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[1], line 11\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file_path\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.pdf\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m pdfplumber\u001B[38;5;241m.\u001B[39mopen(file_path) \u001B[38;5;28;01mas\u001B[39;00m pdf:\n\u001B[1;32m---> 11\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m page \u001B[38;5;129;01min\u001B[39;00m pdf\u001B[38;5;241m.\u001B[39mpages])\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfplumber\\page.py:538\u001B[0m, in \u001B[0;36mPage.extract_text\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_text\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m--> 538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_textmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtuplify_list_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mas_string\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfplumber\\page.py:515\u001B[0m, in \u001B[0;36mPage._get_textmap\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    513\u001B[0m     defaults\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayout_height\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheight})\n\u001B[0;32m    514\u001B[0m full_kwargs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefaults, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs}\n\u001B[1;32m--> 515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mchars_to_textmap(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchars\u001B[49m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfull_kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfplumber\\container.py:52\u001B[0m, in \u001B[0;36mContainer.chars\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchars\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_obj_list:\n\u001B[1;32m---> 52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobjects\u001B[49m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchar\u001B[39m\u001B[38;5;124m\"\u001B[39m, [])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfplumber\\page.py:347\u001B[0m, in \u001B[0;36mPage.objects\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_objects\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_objects\n\u001B[1;32m--> 347\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_objects: Dict[\u001B[38;5;28mstr\u001B[39m, T_obj_list] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_objects\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfplumber\\page.py:451\u001B[0m, in \u001B[0;36mPage.parse_objects\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_objects\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, T_obj_list]:\n\u001B[0;32m    450\u001B[0m     objects: Dict[\u001B[38;5;28mstr\u001B[39m, T_obj_list] \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 451\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_layout_objects(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayout\u001B[49m\u001B[38;5;241m.\u001B[39m_objs):\n\u001B[0;32m    452\u001B[0m         kind \u001B[38;5;241m=\u001B[39m obj[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject_type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    453\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m kind \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manno\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfplumber\\page.py:277\u001B[0m, in \u001B[0;36mPage.layout\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    271\u001B[0m device \u001B[38;5;241m=\u001B[39m PDFPageAggregatorWithMarkedContent(\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpdf\u001B[38;5;241m.\u001B[39mrsrcmgr,\n\u001B[0;32m    273\u001B[0m     pageno\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_number,\n\u001B[0;32m    274\u001B[0m     laparams\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpdf\u001B[38;5;241m.\u001B[39mlaparams,\n\u001B[0;32m    275\u001B[0m )\n\u001B[0;32m    276\u001B[0m interpreter \u001B[38;5;241m=\u001B[39m PDFPageInterpreter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpdf\u001B[38;5;241m.\u001B[39mrsrcmgr, device)\n\u001B[1;32m--> 277\u001B[0m \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_page\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_obj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layout: LTPage \u001B[38;5;241m=\u001B[39m device\u001B[38;5;241m.\u001B[39mget_result()\n\u001B[0;32m    279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layout\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdfinterp.py:997\u001B[0m, in \u001B[0;36mPDFPageInterpreter.process_page\u001B[1;34m(self, page)\u001B[0m\n\u001B[0;32m    995\u001B[0m     ctm \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39mx0, \u001B[38;5;241m-\u001B[39my0)\n\u001B[0;32m    996\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mbegin_page(page, ctm)\n\u001B[1;32m--> 997\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_contents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresources\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    998\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mend_page(page)\n\u001B[0;32m    999\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdfinterp.py:1016\u001B[0m, in \u001B[0;36mPDFPageInterpreter.render_contents\u001B[1;34m(self, resources, streams, ctm)\u001B[0m\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_resources(resources)\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_state(ctm)\n\u001B[1;32m-> 1016\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstreams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdfinterp.py:1021\u001B[0m, in \u001B[0;36mPDFPageInterpreter.execute\u001B[1;34m(self, streams)\u001B[0m\n\u001B[0;32m   1019\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m, streams: Sequence[\u001B[38;5;28mobject\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1020\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1021\u001B[0m         parser \u001B[38;5;241m=\u001B[39m \u001B[43mPDFContentParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstreams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m PSEOF:\n\u001B[0;32m   1023\u001B[0m         \u001B[38;5;66;03m# empty page\u001B[39;00m\n\u001B[0;32m   1024\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdfinterp.py:251\u001B[0m, in \u001B[0;36mPDFContentParser.__init__\u001B[1;34m(self, streams)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mistream \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# PSStackParser.__init__(fp=None) is safe only because we've overloaded\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# all the methods that would attempt to access self.fp without first\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calling self.fillfp().\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mPSStackParser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\psparser.py:545\u001B[0m, in \u001B[0;36mPSStackParser.__init__\u001B[1;34m(self, fp)\u001B[0m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, fp: BinaryIO) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 545\u001B[0m     \u001B[43mPSBaseParser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    546\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset()\n\u001B[0;32m    547\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\psparser.py:193\u001B[0m, in \u001B[0;36mPSBaseParser.__init__\u001B[1;34m(self, fp)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, fp: BinaryIO) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp \u001B[38;5;241m=\u001B[39m fp\n\u001B[1;32m--> 193\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseek\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdfinterp.py:263\u001B[0m, in \u001B[0;36mPDFContentParser.seek\u001B[1;34m(self, pos)\u001B[0m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mseek\u001B[39m(\u001B[38;5;28mself\u001B[39m, pos: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 263\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfillfp\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    264\u001B[0m     PSStackParser\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;28mself\u001B[39m, pos)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdfinterp.py:260\u001B[0m, in \u001B[0;36mPDFContentParser.fillfp\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PSEOF(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected EOF, file truncated?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 260\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp \u001B[38;5;241m=\u001B[39m BytesIO(\u001B[43mstrm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdftypes.py:396\u001B[0m, in \u001B[0;36mPDFStream.get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_data\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbytes\u001B[39m:\n\u001B[0;32m    395\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 396\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    397\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    398\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pdfminer\\pdftypes.py:336\u001B[0m, in \u001B[0;36mPDFStream.decode\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m LITERALS_FLATE_DECODE:\n\u001B[0;32m    334\u001B[0m     \u001B[38;5;66;03m# will get errors if the document is encrypted.\u001B[39;00m\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 336\u001B[0m         data \u001B[38;5;241m=\u001B[39m zlib\u001B[38;5;241m.\u001B[39mdecompress(data)\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m zlib\u001B[38;5;241m.\u001B[39merror \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    339\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mSTRICT:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "eadd0545-96e1-4f32-9548-a99bd8790e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T03:18:00.547443Z",
     "start_time": "2024-10-24T03:16:35.073017Z"
    }
   },
   "source": [
    "import os # STEP 1 \n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "# Set the directory and the path to the Excel file\n",
    "directory = 'E:/MGM UDICT/Analytica'\n",
    "excel_path = \"E:/MGM UDICT/Analytica/ctry.xlsx\"\n",
    "\n",
    "# Load the existing Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Function to extract text from PDF files\n",
    "def extract_text_from_file(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            return ''.join([page.extract_text() for page in pdf.pages])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Dictionary to hold the extracted texts\n",
    "book_texts = {}\n",
    "\n",
    "# Loop through the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.startswith('.'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            text = extract_text_from_file(file_path)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            book_title = filename.split('.')[0]  # Get the title without the extension\n",
    "            book_texts[book_title] = text\n",
    "\n",
    "            \n",
    "\n",
    "# Add the extracted text as a new column in the original DataFrame\n",
    "df['Extracted Text'] = df['Name of the Book'].map(book_texts)\n",
    "\n",
    "# Save the modified DataFrame back to the same Excel file\n",
    "df.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f\"Extracted text has been added to {excel_path}.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alankar.pdf...\n",
      "Processing GandhiAutobio_morallessons.pdf...\n",
      "Processing godan.pdf...\n",
      "Processing truth_is_god.pdf...\n",
      "Extracted text has been added to E:/MGM UDICT/Analytica/ctry.xlsx.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T03:18:55.106133Z",
     "start_time": "2024-10-24T03:18:54.840511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os #step 2 \n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import nltk\n",
    "\n",
    "import shutil\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download (\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Ensure you have downloaded necessary NLTK resources\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while downloading NLTK resources: {e}\")\n",
    "\n",
    "# Set the path to the existing Excel file\n",
    "excel_path = \"E:/MGM UDICT/Analytica/ctry.xlsx\"\n",
    "\n",
    "# Load the existing Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Tokenization, stopword removal, lowercase conversion, and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):  # Check for NaN values\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word.isalpha()]  # Remove punctuation and stopwords\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Apply preprocessing to the 'Extracted Text' column and create a new column 'Processed Text'\n",
    "df['Tokenized Text'] = df['Extracted Text'].apply(preprocess_text)\n",
    "\n",
    "# Write to a temporary file\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_file:\n",
    "    temp_file_path = temp_file.name\n",
    "\n",
    "# Save the modified DataFrame to the temporary file\n",
    "df.to_excel(temp_file_path, index=False)\n",
    "\n",
    "# Copy the temporary file to the original file location\n",
    "shutil.copy2(temp_file_path, excel_path)\n",
    "\n",
    "# Remove the temporary file\n",
    "os.remove(temp_file_path)\n",
    "\n",
    "print(f\"Processed text has been added to {excel_path}.\")\n"
   ],
   "id": "132fb83f8674fa20",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Samyak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samyak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Samyak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Samyak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text has been added to E:/MGM UDICT/Analytica/ctry.xlsx.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T01:48:50.143894Z",
     "start_time": "2024-10-24T01:48:50.092395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Set the path to the Excel file\n",
    "excel_path = \"E:/MGM UDICT/Analytica/ctry.xlsx\"\n",
    "\n",
    "# Load the existing Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Function to extract text from PDF files from a URL\n",
    "def extract_text_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        print(f\"Successfully fetched PDF from {url}.\")  # Debug print\n",
    "        \n",
    "        # Check content type\n",
    "        if 'application/pdf' not in response.headers.get('Content-Type', ''):\n",
    "            print(f\"URL {url} is not a PDF file.\")\n",
    "            return None\n",
    "        \n",
    "        with pdfplumber.open(BytesIO(response.content)) as pdf:\n",
    "            text = ''.join([page.extract_text() for page in pdf.pages])\n",
    "            if text:\n",
    "                print(f\"Extracted text from {url} (length: {len(text)} characters).\")  # Debug print\n",
    "            else:\n",
    "                print(f\"No text found in {url}.\")  # Debug print\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Dictionary to hold the extracted texts\n",
    "book_texts = {}\n",
    "\n",
    "# Loop through the rows in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if 'Link' in row and pd.notna(row['Link']):  # Ensure the Link column exists and is not NaN\n",
    "        url = row['Link']\n",
    "        print(f\"Processing {url}...\")\n",
    "        text = extract_text_from_url(url)\n",
    "        if text is not None:\n",
    "            book_title = row['Name of the Book']  # Use the title from the existing DataFrame\n",
    "            book_texts[book_title] = text\n",
    "\n",
    "# Add the extracted text as a new column in the original DataFrame\n",
    "df['Extracted Text'] = df['Name of the Book'].map(book_texts)\n",
    "\n",
    "# Save the modified DataFrame back to the same Excel file\n",
    "df.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f\"Extracted text has been added to {excel_path}.\")\n"
   ],
   "id": "21909b950889d397",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text has been added to E:/MGM UDICT/Analytica/ctry.xlsx.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d514e484b3ded569"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
